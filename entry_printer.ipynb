{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pymatgen.core import Composition\n",
    "from pymatgen.core.periodic_table import get_el_sp\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from zoneinfo import ZoneInfo\n",
    "import DataTools.compositionVector as cd2cv\n",
    "# import fire\n",
    "from pprint import pprint\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Process name unifier\n",
    "\n",
    "def processNameUnifier(s: str):\n",
    "    exceptions = []\n",
    "\n",
    "    if s in exceptions:\n",
    "        return s\n",
    "    elif s.isupper():\n",
    "        return s\n",
    "    else:\n",
    "        return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Processes processing string into a unified-form process list\n",
    "\n",
    "def processStr2list(s):\n",
    "    ls = []\n",
    "    s = s.replace(' ','')\n",
    "    tempLs = list(s.split('+'))\n",
    "    for process in tempLs:\n",
    "        if process[0].isdigit():\n",
    "            for i in range(int(process[0])):\n",
    "                ls.append(processNameUnifier(process[1:]))\n",
    "        else:\n",
    "            ls.append(processNameUnifier(process))\n",
    "    if ls.__len__()>0:\n",
    "        return [ls, ls.__len__()]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Unifies phase names in the database\n",
    "# If composition -> keep as is\n",
    "# if all uppercase (e.g. BCC, FCC) -> keep as is\n",
    "# otherwise -> make all lowercase\n",
    "\n",
    "def phaseNameUnifier(s):\n",
    "    exceptionToUpper = ['b0', 'b1', 'b2', 'a0', 'a1', 'a2']\n",
    "    replaceDict = {'bulkmetallic\\nglass' : 'amorphous', 'bcc' : 'BCC', 'fcc' : 'FCC', 'LAVES' : 'laves'}\n",
    "\n",
    "    try:\n",
    "        isComp = Composition(s).valid\n",
    "    except Exception as e:\n",
    "        isComp = False\n",
    "\n",
    "    if s in exceptionToUpper:\n",
    "        return s.upper()\n",
    "    elif s in replaceDict:\n",
    "        return replaceDict[s]\n",
    "    elif isComp:\n",
    "        return s\n",
    "    elif s.isupper():\n",
    "        return s\n",
    "    else:\n",
    "        return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Transforms the structure string into a list of\n",
    "# individual phases, interpreting (1) multiple phases\n",
    "# of the same type, (2) composition-defined phases, and\n",
    "# (3) named phases. Processes them in a unified way.\n",
    "\n",
    "def structStr2list(s: str):\n",
    "    ls = []\n",
    "\n",
    "    s = s.replace(' ','')\n",
    "    tempLs = list(s.split('+'))\n",
    "    for phase in tempLs:\n",
    "        if phase[0].isdigit():\n",
    "            for i in range(int(phase[0])):\n",
    "                ls.append(phaseNameUnifier(phase[1:]))\n",
    "        else:\n",
    "            ls.append(phaseNameUnifier(phase))\n",
    "    ls.sort()\n",
    "    if ls.__len__()>0:\n",
    "        return [ls, ls.__len__()]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Modify composition string from the template into a unified\n",
    "# representation of (1) IUPAC standardized formula, (2) pymatgen dictionary\n",
    "# composition object, (3) anonymized formula, (4) reduced formula, (5) chemical system,\n",
    "# and (6) number of components\n",
    "\n",
    "def percentileFormula(cd: dict):\n",
    "    order = sorted(cd.keys(), key=lambda s: get_el_sp(s).iupac_ordering)\n",
    "    return ' '.join([f'{el}{round(100*cd[el], 1):g}' for el in order])\n",
    "\n",
    "def relationalFormula(cd: dict):\n",
    "    order = sorted(cd.keys(), key=lambda s: get_el_sp(s).iupac_ordering)\n",
    "    lowest = min([v for v in cd.values() if v>0.005])\n",
    "    return ' '.join([f'{el}{round(cd[el]/lowest, 2):g}' for el in order])\n",
    "\n",
    "def compStr2compList(s: str):\n",
    "    try:\n",
    "        compObj = Composition(s).reduced_composition\n",
    "        if not compObj.valid:\n",
    "            print(\"Composition invalid\")\n",
    "        return [compObj.iupac_formula,\n",
    "                dict(compObj.fractional_composition.as_dict()),\n",
    "                percentileFormula(dict(compObj.fractional_composition.as_dict())),\n",
    "                relationalFormula(dict(compObj.fractional_composition.as_dict())),\n",
    "                compObj.anonymized_formula,\n",
    "                compObj.reduced_formula,\n",
    "                compObj.chemical_system,\n",
    "                compObj.chemical_system.split('-'),\n",
    "                compObj.__len__()]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        raise ValueError(\"Warning! Can't parse composition!: \"+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1412350164.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    compList =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#%% Convert a pair of metadata and data into ULTERA Database datapoint\n",
    "def datapoint2entry(dataP, printOuts=True):\n",
    "    entry = {'marker': {}, 'material' : {}, 'property' : {}, 'reference' : {}}\n",
    "\n",
    "    # composition\n",
    "    try:\n",
    "        compList = compStr2compList(dataP['Composition'])\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        compList = \n",
    "        raise ValueError(\"Could not parse the composition! Required for upload. Aborting upload!\")\n",
    "    \n",
    "    # material\n",
    "    entry['material'].update({\n",
    "            'rawFormula': dataP['Composition'],\n",
    "            'formula': compList[0],\n",
    "            'compositionDictionary' : compList[1],\n",
    "            'percentileFormula': compList[2],\n",
    "            'relationalFormula': compList[3],\n",
    "            'compositionVector': cd2cv.compDict2Vec(compList[1]),\n",
    "            'anonymizedFormula' : compList[4],\n",
    "            'reducedFormula' : compList[5],\n",
    "            'system' : compList[6],\n",
    "            'elements' : compList[7],\n",
    "            'nComponents' : compList[8]})\n",
    "\n",
    "    # structure\n",
    "    if 'Structure' in dataP:\n",
    "        if dataP['Structure'] is not None:\n",
    "            structList = structStr2list(dataP['Structure'])\n",
    "            entry['material'].update({\n",
    "                'structure': structList[0],\n",
    "                'nPhases': structList[1]})\n",
    "        else:\n",
    "            if printOuts:\n",
    "                print('No structure data!')\n",
    "\n",
    "    # processing\n",
    "    if 'Processing' in dataP:\n",
    "        if dataP['Processing'] is not None:\n",
    "            processingList = processStr2list(dataP['Processing'])\n",
    "            entry['material'].update({\n",
    "                    'processes' : processingList[0],\n",
    "                    'nProcessSteps' : processingList[1]})\n",
    "        else:\n",
    "            if printOuts:\n",
    "                print('No process data!')\n",
    "\n",
    "    # comment\n",
    "    if 'Material Comment' in dataP:\n",
    "        if dataP['Material Comment'] is not None:\n",
    "            entry['material'].update({\n",
    "                    'comment' : dataP['Material Comment']})\n",
    "\n",
    "    if 'Temperature [K]' in dataP:\n",
    "        # If there is temperature reported, regardless of property report, note the temperature of material\n",
    "        if dataP['Temperature [K]'] is not None:\n",
    "            entry['material'].update({\n",
    "                'observationTemperature': float(dataP['Temperature [K]'])})\n",
    "\n",
    "    if 'Name' in dataP:\n",
    "        # Requires: Name and Value\n",
    "        if dataP['Name'] is not None:\n",
    "            entry['property'].update({\n",
    "                'name' : dataP['Name'],\n",
    "                'value': float(dataP['Value [SI]'])})\n",
    "\n",
    "            # If property has a name, go through all of property parameters and value\n",
    "            if 'Source' in dataP:\n",
    "                if dataP['Source'] is not None:\n",
    "                    entry['property'].update({\n",
    "                        'source': dataP['Source']})\n",
    "            if 'Property Parameters' in dataP:\n",
    "                if dataP['Property Parameters'] is not None:\n",
    "                    entry['property'].update({\n",
    "                        'parameters': dataP['Property Parameters']})\n",
    "            if 'Temperature [K]' in dataP:\n",
    "                if dataP['Temperature [K]'] is not None:\n",
    "                    entry['property'].update({\n",
    "                        'temperature': float(dataP['Temperature [K]'])})\n",
    "            if 'Unit [SI]' in dataP:\n",
    "                if dataP['Unit [SI]'] is not None:\n",
    "                    entry['property'].update({\n",
    "                        'unitName': dataP['Unit [SI]']})\n",
    "        else:\n",
    "            del entry['property']\n",
    "            if printOuts:\n",
    "                print('No property data or error occurred!')\n",
    "\n",
    "    if 'DOI' in dataP:\n",
    "        # Requires DOI\n",
    "        if 'DOI' in dataP:\n",
    "            if dataP['DOI'] is not None:\n",
    "                entry['reference'].update({\n",
    "                        'doi' : dataP['DOI']})\n",
    "                if 'Pointer' in dataP:\n",
    "                    if dataP['Pointer'] is not None:\n",
    "                        entry['reference'].update({\n",
    "                            'pointer': dataP['Pointer']})\n",
    "            else:\n",
    "                del entry['reference']\n",
    "                if printOuts:\n",
    "                    print('No reference data!')\n",
    "\n",
    "    return entry\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     fire.Fire(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function to generate 2d array of [[raw formula],[percentile formula],[property name],[property value]]\n",
    "# for the materials in dataset\n",
    "\n",
    "def arrayGenerator(parsed):\n",
    "    dataset = []\n",
    "    prop_values = []\n",
    "    prop_names = []\n",
    "    raw_formulas = []\n",
    "    percentile_formulas = []\n",
    "    validations = []\n",
    "    markers = []\n",
    "\n",
    "    for datapoint in parsed:\n",
    "        if (datapoint2entry(datapoint)):\n",
    "            dataset.append[datapoint2entry(datapoint)]\n",
    "        else:\n",
    "            print(str(e))\n",
    "            failed_dataset.append(datapoint)\n",
    "            markers.append('🔴')\n",
    "            pass\n",
    "            # raise ValueError(\"Could not parse the composition! Required for upload. Aborting upload!\")\n",
    "\n",
    "    # try:\n",
    "    #     dataset = [datapoint2entry(datapoint) for datapoint in parsed]\n",
    "    # except Exception as e:\n",
    "    #     print(str(e))\n",
    "    #     markers.append('🔴')\n",
    "    #     # raise ValueError(\"Could not parse the composition! Required for upload. Aborting upload!\")\n",
    "\n",
    "    # for datapoint in parsed:\n",
    "    #     try:\n",
    "    #         dataset = [datapoint2entry(datapoint)]\n",
    "    #     except Exception as e:\n",
    "    #         print(str(e))\n",
    "    #         failed_data.append(datapoint)\n",
    "    #         markers.append('🔴')\n",
    "    #         # pass\n",
    "    #         # raise ValueError(\"Could not parse the composition! Required for upload. Aborting upload!\")\n",
    "\n",
    "    def adjustLen(strArray: List[str]) -> List[str]:\n",
    "        max_str_length = max([len(f) for f in strArray])\n",
    "        return [f'{formula:<{max_str_length}}' for formula in strArray]\n",
    "\n",
    "    for data in dataset:\n",
    "        # bool_markers.append(int(data['marker']['boolMarker']))\n",
    "        if 'material' in data:\n",
    "            raw_formulas.append(data['material']['rawFormula'])\n",
    "            percentile_formulas.append(data['material']['percentileFormula'])\n",
    "        else:\n",
    "            raw_formulas.append('')\n",
    "            percentile_formulas.append('')\n",
    "        if 'property' in data:\n",
    "            prop_names.append(data['property']['name'])\n",
    "            prop_values.append(data['property']['value'])\n",
    "        else:\n",
    "            prop_names.append('')\n",
    "            prop_values.append(0)\n",
    "    \n",
    "    raw_formulas = adjustLen(raw_formulas)\n",
    "    percentile_formulas = adjustLen(percentile_formulas)\n",
    "\n",
    "    property_condition = 'UTS'\n",
    "    value_condition = 6e8\n",
    "\n",
    "    for prop, value in zip(prop_names, prop_values):\n",
    "        # if bool_marker == False:\n",
    "        #     validations.append('')\n",
    "        #     markers.append('🔴')\n",
    "        if value >= value_condition and prop == property_condition:\n",
    "            validations.append(f\"High {property_condition} value is {value}\")\n",
    "            markers.append('🟠')\n",
    "        else:\n",
    "            validations.append('')\n",
    "            markers.append('🟢')\n",
    "\n",
    "    return [\n",
    "        f'- {marker}  {raw_formula} | {percentile_formula} | {prop_name} | {validation} \\n'\n",
    "        for marker, raw_formula, percentile_formula, prop_name, validation \n",
    "        in zip(markers, raw_formulas, percentile_formulas, prop_names, validations)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing data.\n",
      "Imported 22 datapoints.\n",
      "\n",
      "No reference data!\n",
      "No property data or error occurred!\n",
      "No property data or error occurred!\n"
     ]
    }
   ],
   "source": [
    "datasheet = 'template_v4_DatasetExample.xlsx'\n",
    "isDatabase = False\n",
    "\n",
    "# get timestamp\n",
    "dateString = datetime.now().strftime('%Y-%d-%b-%H-%M')\n",
    "\n",
    "### Logging progress into Markdown file\n",
    "MdLogger = open('PyQAlloyReport'+dateString+'.md', \"w\")\n",
    "MdLogger.write('\\n# PyQAlloyReport '+dateString+'\\n\\n')\n",
    "MdLogger.write('**Legend:** \\n\\n🟢 Successful Upload / 🟠 Abnormal Upload / 🔴 Failed Upload\\n\\n')\n",
    "MdLogger.write('## Composition --> Result \\n')\n",
    "\n",
    "# Import data\n",
    "print('\\nImporting data.')\n",
    "df2 = pd.read_excel(datasheet, usecols=\"A:N\", nrows=5000, skiprows=8)\n",
    "result = df2.to_json(orient=\"records\")\n",
    "parsed = json.loads(result, strict=False)\n",
    "print('Imported '+str(parsed.__len__())+' datapoints.\\n')\n",
    "\n",
    "## Convert data into database datapoints and upload\n",
    "results = arrayGenerator(parsed)\n",
    "for result in results:\n",
    "    MdLogger.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_formulas = ['1', '1000', '100']\n",
    "\n",
    "# max_str_length = max([len(f) for f in raw_formulas])\n",
    "\n",
    "# prforms = [f'{formula:<{max_str_length}}' for formula in raw_formulas]\n",
    "# print(prforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for finding max str length from list\n",
    "\n",
    "# test_list = ['1', '100', '1000', '10000']\n",
    "\n",
    "# str_lengths = [len(s) for s in test_list]\n",
    "# longest_str_length = (max(str_lengths))\n",
    "\n",
    "# print(longest_str_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if property values of materials in dataset meet a certain condition\n",
    "# ex: checking if the material property given is UTS, and if yes, then checking if UTS value > 6e8\n",
    "\n",
    "# property = 'UTS'\n",
    "# value_condition = 6e8\n",
    "\n",
    "# def propertyChecker(uploadEntry):\n",
    "#     mydata = []\n",
    "#     prop_values = []\n",
    "#     mat_formulas = []\n",
    "#     mydata.append(uploadEntry)\n",
    "#     for data in mydata:\n",
    "#         for category, subcategory in data.items():\n",
    "#             if category == 'property':\n",
    "#                 if subcategory['name'] == property and subcategory['value'] >= value_condition:\n",
    "#                     prop_values.append(subcategory['value'])\n",
    "#                     mat = data['material']\n",
    "#                     formula = mat['formula']\n",
    "#                     mat_formulas.append(formula)\n",
    "#                     return True\n",
    "#                 else:\n",
    "#                     return False\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata = []\n",
    "# prop_values = []\n",
    "# mat_formulas = []\n",
    "# for data in mydata:\n",
    "#     for category, subcategory in data.items():\n",
    "#         if category == 'property':\n",
    "#             if subcategory['name'] == property and subcategory['value'] >= value_condition:\n",
    "#                 prop_values.append(subcategory['value'])\n",
    "#                 mat = data['material']\n",
    "#                 formula = mat['formula']\n",
    "#                 mat_formulas.append(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasheet = 'template_v4_DatasetExample.xlsx'\n",
    "# isDatabase = False\n",
    "\n",
    "# # Import metadata\n",
    "# print('Reading the metadata.')\n",
    "# metaDF = pd.read_excel(datasheet, usecols=\"A:F\", nrows=4)\n",
    "# meta = metaDF.to_json(orient=\"split\")\n",
    "# metaParsed = json.loads(meta, strict=False)['data']\n",
    "\n",
    "# # get timestamp\n",
    "# dateString = datetime.now().strftime('%Y-%d-%b-%H-%M')\n",
    "\n",
    "# # Format metadata into a dictionary\n",
    "# metaData = {\n",
    "#     'source': 'LIT',\n",
    "#     'name': metaParsed[0][1],\n",
    "#     'email': metaParsed[1][1],\n",
    "#     'directFetch': metaParsed[2][1],\n",
    "#     'handFetch': metaParsed[3][1],\n",
    "#     'comment': metaParsed[0][5],\n",
    "#     'timeStamp': datetime.now(ZoneInfo('America/New_York')),\n",
    "#     'dataSheetName': datasheet\n",
    "# }\n",
    "\n",
    "# if isDatabase:\n",
    "#     metaData.update({'parentDatabase': target})\n",
    "#     metaData.update({'handFetch': False})\n",
    "\n",
    "# print('Data credited to: '+metaParsed[0][1])\n",
    "# print('Contact email: '+metaParsed[1][1])\n",
    "# pprint(metaData)\n",
    "\n",
    "# ### Logging progress into Markdown file\n",
    "# MdLogger = open('PyQAlloyReport'+dateString+'.md', \"w\")\n",
    "# MdLogger.write('\\n#PyQAlloyReport '+dateString+'\\n\\n')\n",
    "# MdLogger.write('**Legend:** \\n\\n🟢 Successful Upload / 🟠 Abnormal Upload / 🔴 Failed Upload\\n\\n')\n",
    "# MdLogger.write('## Composition --> Result \\n')\n",
    "\n",
    "# # Import data\n",
    "# print('\\nImporting data.')\n",
    "# df2 = pd.read_excel(datasheet, usecols=\"A:N\", nrows=5000, skiprows=8)\n",
    "# result = df2.to_json(orient=\"records\")\n",
    "# parsed = json.loads(result, strict=False)\n",
    "# print('Imported '+str(parsed.__len__())+' datapoints.\\n')\n",
    "\n",
    "# # Convert metadata and data into database datapoints and upload\n",
    "# for datapoint in parsed:\n",
    "#     comp = datapoint['Composition'].replace(' ','')\n",
    "#     print('Processing: '+comp)\n",
    "#     try:\n",
    "#         uploadEntry = datapoint2entry(metaData, datapoint)\n",
    "#         MdLogger.write('- 🟢 '+comp+' --> Success!')\n",
    "#         propertyCheck = propertyChecker(uploadEntry)\n",
    "#         if propertyCheck == True:\n",
    "#             MdLogger.write(' Hey! High '+property+ '!!!')\n",
    "#         MdLogger.write('\\n')\n",
    "\n",
    "#         matArray = arrayGenerator(uploadEntry)\n",
    "\n",
    "#     except ValueError as e:\n",
    "#         exceptionMessage = str(e)\n",
    "#         print(exceptionMessage)\n",
    "#         MdLogger.write('- 🔴 '+comp+' --> Fail! <------- '+exceptionMessage+'\\n')\n",
    "#         print('Upload failed!\\n')\n",
    "#         pass\n",
    "# MdLogger.close()\n",
    "\n",
    "# # matArray = arrayGenerator(uploadEntry)\n",
    "# pprint(matArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata = []\n",
    "# mydata.append(uploadEntry)\n",
    "# pprint(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata = []\n",
    "# prop_values = []\n",
    "# prop_names = []\n",
    "# raw_formulas = []\n",
    "# prcnt_formulas = []\n",
    "# uploadEntry = datapoint2entry(metaData, datapoint)\n",
    "\n",
    "# for data in uploadEntry:\n",
    "# mydata.append(uploadEntry)\n",
    "\n",
    "# pprint(mydata)\n",
    "\n",
    "# for data in mydata:\n",
    "#     for category, subcategory in data.items():\n",
    "#         for subcategory, supsubcategory in category.items():\n",
    "#         # if category == 'property':\n",
    "#             # if subcategory['name'] == property and subcategory['value'] >= value_condition:\n",
    "#         # prop_values.append(subcategory['value'])\n",
    "#             mat = category['material']\n",
    "#             raw_formula = mat['rawFormula']\n",
    "#             prcnt_formula = mat['percentileFormula']\n",
    "#             raw_formulas.append(raw_formula)\n",
    "#             prcnt_formulas.append(prcnt_formula)\n",
    "#             prop = category['property']\n",
    "#             prop_name = prop['name']\n",
    "#             prop_val = prop['value']\n",
    "#             prop_values.append(prop_val)\n",
    "#             prop_names.append(prop_name)\n",
    "\n",
    "# pprint(raw_formulas)\n",
    "# pprint(prcnt_formulas)\n",
    "# pprint(prop_names)\n",
    "# pprint(prop_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata = []\n",
    "# prop_values = []\n",
    "# prop_names = []\n",
    "# raw_formulas = []\n",
    "# percent_formulas = []\n",
    "# mydata.append(uploadEntry)\n",
    "# for data in mydata:\n",
    "#     for section, parameter in data.items():\n",
    "#         if section == 'material':\n",
    "#             raw_formulas.append(parameter['rawFormula'])\n",
    "#             percent_formulas.append(parameter['percentileFormula'])\n",
    "#         if section == 'property':\n",
    "#             prop_names.append(parameter['name'])\n",
    "#             prop_values.append(parameter['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(mydata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate thru uploadEntry (appended to mydata list), access entries for property, \n",
    "# # make into list, tell if UTS greater than 600 Mpa = 6e8 Pa\n",
    "\n",
    "# props = []\n",
    "# mats = []\n",
    "# i = 0\n",
    "# for data in mydata:\n",
    "#     for category, subcategory in data.items():\n",
    "#         i+=1\n",
    "#         if category == 'property':\n",
    "#             if subcategory['name'] == 'UTS' and subcategory['value'] >= 6e8:\n",
    "#                 props.append(subcategory['value'])\n",
    "#                 mat = data.get('material')\n",
    "#                 formula = mat.get('formula')\n",
    "#                 mats.append(formula)           \n",
    "\n",
    "# valid_mat_props = {mats[i]: props[i] for i in range(len(mats))}\n",
    "\n",
    "# print(props)\n",
    "# print(mats)\n",
    "# print(valid_mat_props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### duplicate code block 9/21 ###\n",
    "\n",
    "# datasheet = 'template_v4_DatasetExample.xlsx'\n",
    "# isDatabase = False\n",
    "\n",
    "# #Import metadata\n",
    "# print('Reading the metadata.')\n",
    "# metaDF = pd.read_excel(datasheet, usecols=\"A:F\", nrows=4)\n",
    "# meta = metaDF.to_json(orient=\"split\")\n",
    "# metaParsed = json.loads(meta, strict=False)['data']\n",
    "\n",
    "# # get timestamp\n",
    "# dateString = datetime.now().strftime('%Y-%d-%b-%H-%M')\n",
    "\n",
    "# # Format metadata into a dictionary\n",
    "# metaData = {\n",
    "#     'source': 'LIT',\n",
    "#     'name': metaParsed[0][1],\n",
    "#     'email': metaParsed[1][1],\n",
    "#     'directFetch': metaParsed[2][1],\n",
    "#     'handFetch': metaParsed[3][1],\n",
    "#     'comment': metaParsed[0][5],\n",
    "#     'timeStamp': datetime.now(ZoneInfo('America/New_York')),\n",
    "#     'dataSheetName': datasheet\n",
    "# }\n",
    "\n",
    "# if isDatabase:\n",
    "#     metaData.update({'parentDatabase': target})\n",
    "#     metaData.update({'handFetch': False})\n",
    "\n",
    "# print('Data credited to: '+metaParsed[0][1])\n",
    "# print('Contact email: '+metaParsed[1][1])\n",
    "# pprint(metaData)\n",
    "\n",
    "# # Logging progress into a CSV table\n",
    "# # dataFileName = datasheet.replace('.xls', '').replace('.xlsx', '')\n",
    "# # logger = open(dataFileName+'_REPORT_'+dateString+'.csv', \"w\")\n",
    "# # logger.write('Composition, Result\\n')\n",
    "\n",
    "# ### Logging progress into Markdown file\n",
    "# MdLogger = open('PyQAlloyReport_'+dateString+'.md', \"w\")\n",
    "# MdLogger.write('Composition, Result\\n')\n",
    "\n",
    "# # Import data\n",
    "# print('\\nImporting data.')\n",
    "# df2 = pd.read_excel(datasheet, usecols=\"A:N\", nrows=5000, skiprows=8)\n",
    "# result = df2.to_json(orient=\"records\")\n",
    "# parsed = json.loads(result, strict=False)\n",
    "# print('Imported '+str(parsed.__len__())+' datapoints.\\n')\n",
    "\n",
    "# # Convert metadata and data into database datapoints and upload\n",
    "# for datapoint in parsed:\n",
    "#     comp = datapoint['Composition'].replace(' ','')\n",
    "#     print('Processing: '+comp)\n",
    "#     try:\n",
    "#         uploadEntry = datapoint2entry(metaData, datapoint)\n",
    "#         MdLogger.write(comp+' ,Success! ')\n",
    "#         propertyCheck = propertyChecker(uploadEntry)\n",
    "#         if propertyCheck == True:\n",
    "#             MdLogger.write('Hey! High '+property+ '!!!')\n",
    "#         MdLogger.write('\\n')\n",
    "\n",
    "#     except ValueError as e:\n",
    "#         exceptionMessage = str(e)\n",
    "#         print(exceptionMessage)\n",
    "#         MdLogger.write(comp + ',Fail!,<-------,'+exceptionMessage+'\\n')\n",
    "#         # print('Upload failed!\\n')\n",
    "#         pass\n",
    "# MdLogger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-string example: generate 100 comps, format left, right, center\n",
    "\n",
    "# comps = []\n",
    "\n",
    "# for i in range(0,100):\n",
    "#     comp = Composition({'Cr':i,'Ni':(100-i)})\n",
    "#     comps.append(comp.formula)\n",
    "\n",
    "# print(comps)\n",
    "\n",
    "# lengths = [len(comp) for comp in comps]\n",
    "# max_str_len = max(lengths)\n",
    "# formatting_len = max_str_len + 6\n",
    "\n",
    "# print(max_str_len)\n",
    "\n",
    "# # left aligned\n",
    "# for comp in comps:\n",
    "#     pprint(f'{comp:<{formatting_len}}')\n",
    "\n",
    "# # right aligned\n",
    "# for comp in comps:\n",
    "#     pprint(f'{comp:>{formatting_len}}')\n",
    "\n",
    "# # center aligned\n",
    "# for comp in comps:\n",
    "#     pprint(f'{comp:^{formatting_len}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
